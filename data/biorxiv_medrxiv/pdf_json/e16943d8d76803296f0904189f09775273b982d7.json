{
    "paper_id": "e16943d8d76803296f0904189f09775273b982d7",
    "metadata": {
        "title": "AutoTriage -An Open Source Edge Computing Raspberry Pi-based Clinical Screening System",
        "authors": [
            {
                "first": "Chaitra",
                "middle": [],
                "last": "Hegde",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Georgia Institute of Technology",
                    "location": {
                        "settlement": "Atlanta",
                        "region": "GA"
                    }
                },
                "email": ""
            },
            {
                "first": "Zifan",
                "middle": [],
                "last": "Jiang",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Georgia Institute of Technology",
                    "location": {
                        "settlement": "Atlanta",
                        "region": "GA"
                    }
                },
                "email": ""
            },
            {
                "first": "Jacob",
                "middle": [],
                "last": "Zelko",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Georgia Institute of Technology",
                    "location": {
                        "settlement": "Atlanta",
                        "region": "GA"
                    }
                },
                "email": ""
            },
            {
                "first": "Pradyumna",
                "middle": [
                    "Byappanahalli"
                ],
                "last": "Suresha",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Georgia Institute of Technology",
                    "location": {
                        "settlement": "Atlanta",
                        "region": "GA"
                    }
                },
                "email": ""
            },
            {
                "first": "Rishikesan",
                "middle": [],
                "last": "Kamaleswaran",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Emory University",
                    "location": {
                        "settlement": "Atlanta",
                        "region": "GA"
                    }
                },
                "email": ""
            },
            {
                "first": "Matt",
                "middle": [
                    "A"
                ],
                "last": "Reyna",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Emory University",
                    "location": {
                        "settlement": "Atlanta",
                        "region": "GA"
                    }
                },
                "email": ""
            },
            {
                "first": "Gari",
                "middle": [
                    "D"
                ],
                "last": "Clifford",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Georgia Institute of Technology",
                    "location": {
                        "settlement": "Atlanta",
                        "region": "GA"
                    }
                },
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "With the recent COVID-19 pandemic, healthcare systems all over the world are struggling to manage the massive increase in emergency department (ED) visits. This has put an enormous demand on medical professionals. Increased wait times in the ED increases the risk of infection transmission. In this work we present an open-source, low cost, off-body system to assist in the automatic triage of patients in the ED based on widely available hardware. The system initially focuses on two symptoms of the infection -fever and cyanosis. The use of visible and far-infrared cameras allows for rapid assessment at a 1m distance, thus reducing the load on medical staff and lowering the risk of spreading the infection within hospitals. Its utility can be extended to a general clinical setting in non-emergency times as well to reduce wait time, channel the time and effort of healthcare professionals to more critical tasks and also prioritize severe cases.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Our system consists of a Raspberry Pi 4, a Google Coral USB accelerator, a Raspberry Pi Camera v2 and a FLIR Lepton 3.5 Radiometry Long-Wave Infrared Camera with an associated IO module. Algorithms running in real-time detect the presence and body parts of individual(s) in view, and segments out the forehead and lip regions using PoseNet. The temperature of the forehead-eye area is estimated from the infrared camera image and cyanosis is assessed from the image of the lips in the visible spectrum. In our preliminary experiments, an accuracy of 97% was achieved for detecting fever and 77% for the detection of cyanosis, with a sensitivity of 91% and area under the receiver operating characteristic curve of 0.91.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "Although preliminary results are promising, we note that the entire system needs to be optimized before use and assessed for efficacy. The use of low-cost instrumentation will not produce temperature readings and identification of cyanosis that is acceptable in many situations. For this reason, we are releasing the full code stack and system design to allow others to rapidly iterate and improve the system. This may be of particular benefit in low-resource settings, and low-to-middle income countries in particular, which are just beginning to be affected by COVID-19.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "With a dramatic increase in emergency department (ED) visit rates over the last four decades, both in the United States and around the world [24, 19, 20, 29] , accurate and timely triage is essential for assuring patients' safety and optimal resource allocation. Crowding in the ED can affect the triage process, leading to longer waiting times for triage, longer ED length of stays and potentially poorer outcomes [14] . More acutely, crowding in ED during a pandemic such as COVID-19 could increase the risk for health professionals as well as patients.",
            "cite_spans": [
                {
                    "start": 141,
                    "end": 145,
                    "text": "[24,",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 146,
                    "end": 149,
                    "text": "19,",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 150,
                    "end": 153,
                    "text": "20,",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 154,
                    "end": 157,
                    "text": "29]",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 415,
                    "end": 419,
                    "text": "[14]",
                    "ref_id": "BIBREF15"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Computer-aided triage systems have been proposed over the years with the help of browser-based applications that exchange information with existing medical records [1] , wearable sensors [11] and automatic initial interpretation of CT scans [12] . However, most existing methods either require significant interaction between the patients and the healthcare workers or need active input from the patients. Hence, there is an emerging need for an automatic triage system that works passively and requires minimal attention and interaction from both patients and health professionals. In this work, we focus on real-time identification of febrile status and cyanosis in patients, since these are two critical symptoms in the recent COVID-19 crisis.",
            "cite_spans": [
                {
                    "start": 164,
                    "end": 167,
                    "text": "[1]",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 187,
                    "end": 191,
                    "text": "[11]",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 241,
                    "end": 245,
                    "text": "[12]",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The Emergency Severity Index (ESI), used by most EDs in the United States [17] , records the febrile state of young children and manifestation of cyanosis in all age groups. While core temperature is difficult to measure non-invasively, there is some evidence that infrared cameras are able to do so to some level of acceptable accuracy [8] . In particular, we considered temperature in the forehead area and color distribution of the lip as indicators for the febrile state and cyanosis.",
            "cite_spans": [
                {
                    "start": 74,
                    "end": 78,
                    "text": "[17]",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 337,
                    "end": 340,
                    "text": "[8]",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Many systems that detect a febrile state via infrared imaging [22, 26, 27, 13] have been reported and evaluated over the years and a deep learning method was introduced for face segmentation in [13] . Cyanosis is a bluish discoloration of the skin or other areas of the peripheral body resulting from poor circulation or inadequate oxygenation of the blood. More specifically, it is due to increased concentration of reduced hemoglobin (Hb) in the circulation and is clinically evident at an oxygen saturation of 85% or less. Mild cyanosis is more challenging to detect. Cyanosis can be observed in the lips, ears, trunk, nailbed, hands and conjunctiva. Circumoral areas (around the mouth) have been compared in detecting cyanosis resulting from arterial hypoxemia. It has been noted that while the tongue is the most sensitive area, the lips are more specific ( [6] , chapter 45). For this work, we therefore focused on the lips, since they are easier to observe than the tongue and have been identified in ED emergency response assessment systems.",
            "cite_spans": [
                {
                    "start": 62,
                    "end": 66,
                    "text": "[22,",
                    "ref_id": "BIBREF25"
                },
                {
                    "start": 67,
                    "end": 70,
                    "text": "26,",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 71,
                    "end": 74,
                    "text": "27,",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 75,
                    "end": 78,
                    "text": "13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 194,
                    "end": 198,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 863,
                    "end": 866,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Our proposed system consists of a low cost minicomputer -a Raspberry Pi (RasPi), a Google Coral USB accelerator tensor processing unit (TPU), a visible camera and a thermal camera, which are all portable and relatively inexpensive. By leveraging object detection and machine learning classification techniques, the system was designed to be capable of segmenting out regions of interest and classify febrile state and cyanosis in real-time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Hardware configuration. Fig. 1 shows the proposed system. The various parts and their approximate costs are: a RasPi 4 with 4 GB of RAM ($55) and a 16 GB microSD card ($7), a Google Coral USB accelerator ($74.99), a visible light (Red, Green and Blue; RGB) RasPi Camera v2 ($10.99) and a FLIR Lepton 3.5 Radiometry Long-Wave Infrared Camera ($200) with its associated IO module ($100). The total offthe-shelf cost of the system is around $450. The visible light and thermal videos are captured at 25hz and 9hz, respectively. The RasPi was used as the main processor which takes in the video streams, processes them and can display the resulting video in real-time on an external monitor (via the HDMI connector). The forehead and lip detection were computed on the Google Coral USB accelerator, since this part of the algorithm required a deep neural network and hence significantly more computational power. The full setup can be seen Overview of algorithms. Our algorithm performs two functions: fever estimation and cyanosis classification. For fever estimation, we detect the forehead region, and for cyanosis classification we detect the lip region. These regions are then analyzed to identify color distributions indicative of fever or cyanosis using a post processing machine learning algorithm. The overall flow is shown in Fig. 3 and a more detailed description of the algorithms now follows. Forehead and lip detection. To detect and segment out the forehead and lips for further analysis, a computer visionbased human pose detection algorithm knows as PoseNet is used [23] . This algorithm uses a convolutional neural network to regress the six degrees of freedom camera pose from a single RGB image in an end-to-end manner with no need for additional engineering or optimisation. PoseNet detects \"keypoints\" -the image coordinates of key parts of the body, such as the elbow, knee, eyes and nose. We use the keypoints of the left and right eye as references to identify a bounding box around the forehead and lips. If we define the distance between the eyes to be D pixels, for the forehead, we use a bounding box that has width 2D and a height 1.2D. The base of the bounding box is 0.2D below the eyes. This ensures that the forehead-eyes area is captured. This is an important site, since the inner canthus of the eye is consistently the warmest area on the head and the most suitable area for fever detection [28] . For the lips, we move a distance D below the eyes and create a bounding box with width D and height 0.5D. These values were set empirically (through trial and error using the authors) to best capture the lips. In future experiments these values can be optimized on larger datasets. Note that the coordinates obtained by applying this heuristic are rounded to the closest integer value. Fig. 4 shows an example of the forehead and lip detection on one of the authors using this approach in the visible spectrum (upper plot) and the corresponding FLIR image (lower plot). Note that the images have slight FOV, image angle and translational differences since the cameras cannot take images from the same location in space and operate at different (non-synchronous) sampling rates.",
            "cite_spans": [
                {
                    "start": 1579,
                    "end": 1583,
                    "text": "[23]",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 2424,
                    "end": 2428,
                    "text": "[28]",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [
                {
                    "start": 24,
                    "end": 30,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF1"
                },
                {
                    "start": 1332,
                    "end": 1338,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 2817,
                    "end": 2823,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF4"
                }
            ],
            "section": "Methods"
        },
        {
            "text": "It is important to note that there are other state-of-theart object detection algorithms that are capable of detecting faces, such as YOLO [25] . YOLO can also be used to segment out the forehead and lips. However, using PoseNet in this implementation allows for rapid deployment on the Google Coral Accelerator TPU and is therefore simple to implement in real time. Another benefit of using PoseNet is that the keypoints generated by it for the rest of the body could potentially be used in the future to further enhance assessment of other symptoms such as posture or balance abnormalities, or behaviors such as vomiting, falls, and tonicclonic seizures.",
            "cite_spans": [
                {
                    "start": 139,
                    "end": 143,
                    "text": "[25]",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Methods"
        },
        {
            "text": "Febrile state detection. Unlike the previous studies, our proposed system detects key points using visible light video and then transforms the coordinates of the bounding boxes of the region of interest (ROI) to coordinates in the thermal video. After finding the ROI in the thermal video, the average of the ten pixels exhibiting the highest temperatures were averaged to produce a final temperature estimate. Lastly, a threshold was set to determine the febrile state.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methods"
        },
        {
            "text": "Thermal output calibration. To achieve a more accurate measurement of the body temperature, we followed the guidelines from the FLIR Lepton 3.5 datasheet [10] and methods detailed in previous studies [13] that used a similar infrared camera and performed the radiometry calibration on the FLIR Lepton camera. The conversion from the 14 bit pixel values from the FLIR Lepton camera to a temperature in Celsius can be written as: 5 .) The reference temperature of the water was measured three times using a Braun IRT6500 thermometer and averaged. The reference has an accuracy of \u00b10.2 \u2022 C within the 35 \u2212 42 \u2022 C measurement range. Also, the top ten pixels in the heat source were selected and averaged as the final output of the FLIR Lepton camera. R (camera responsivity) and O (the offset) in Eq. 1 are then fitted using the above-described experiment via a nonlinear least square method with soft l1 loss as follows:",
            "cite_spans": [
                {
                    "start": 154,
                    "end": 158,
                    "text": "[10]",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 200,
                    "end": 204,
                    "text": "[13]",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [
                {
                    "start": 428,
                    "end": 429,
                    "text": "5",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Methods"
        },
        {
            "text": "The Root Mean Square Error (RMSE) metric was used to evaluate the fitting error. The fitted curve was then implemented to convert pixels values to temperature output.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Methods"
        },
        {
            "text": "Since the forehead-eyes area is detected in the visible light image sequences, a coordinates transformation is needed to find the forehead-eyes location in the thermal video. The transformation depends on the resolutions and FOVs of the two cameras and the relative physical displacement between them. The resolution of the RasPi Camera was set at 1640 \u00d7 1232 pixels and the corresponding FOV was 62.2 \u2022 horizontally and 48.8 \u2022 vertically. The resolution of the FLIR Lepton camera was set to be 160 \u00d7 120 pixels and the corresponding FOV was 57 \u2022 horizontally and 71 \u2022 diagonally. Since there only exist less than 2 cm distance and consequently a small angle difference between the cameras, the transformation can be expressed as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ROI registration in thermal video."
        },
        {
            "text": "Where xL, yL are the coordinates for the left vertex of the bounding box and xR, yR denote the right vertex.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ROI registration in thermal video."
        },
        {
            "text": "x ratio , y ratio are the resolution ratios between RasPi Camera and FLIR Lepton Camera. And x bias , y bias are the view difference caused by different FOVs and can be calculated as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ROI registration in thermal video."
        },
        {
            "text": "(4) In practice, because of the angle difference and distance between the cameras, which varies with different mounting schemes, empirical offsets were added to ensure accurate transformation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ROI registration in thermal video."
        },
        {
            "text": "Threshold selection. The Merck Manual [3] defines fever as an elevated body temperature that is higher than 37.8 \u2022 C orally [16] and Cleveland clinic advised patients with a fever higher than 100.4 \u2022 F / 38 \u2022 C to isolate themselves as of April 2020 [7] . Forehead (temporal) temperature is usually 0.5 \u2022 F (0.3 \u2022 C) to 1 \u2022 F (0.6 \u2022 C) lower than an oral temperature measurement [9] . Experimental setup. The preliminary test was conducted on a healthy male subject. A heated cloth was put on the subject's forehead to raise the temperature of the subject's forehead. The estimated temperature from the proposed system was recorded immediately after a measurement from the thermometer in the center of the subject's forehead. The subject was sitting one meter away from the cameras. The RMSE between the estimated value and temperature from the thermometer was used to evaluate the accuracy of our proposed system.",
            "cite_spans": [
                {
                    "start": 38,
                    "end": 41,
                    "text": "[3]",
                    "ref_id": null
                },
                {
                    "start": 124,
                    "end": 128,
                    "text": "[16]",
                    "ref_id": null
                },
                {
                    "start": 250,
                    "end": 253,
                    "text": "[7]",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 379,
                    "end": 382,
                    "text": "[9]",
                    "ref_id": "BIBREF9"
                }
            ],
            "ref_spans": [],
            "section": "ROI registration in thermal video."
        },
        {
            "text": "Once the lip region is segmented from the face, an algorithm to detect cyanosis is applied to the region. Various algorithms were tested on a small dataset. The algorithm that performed the best is used to classify images from the camera as cyanotic or non-cyanotic. Leave-one-out cross validation method was used to report the results.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Cyanosis detection."
        },
        {
            "text": "We created a small dataset consisting of images of cyanotic and non-cyanotic lips from the internet. It consists of 35 images of cyanotic lips and 35 images of non-cyanotic lips. The images belong to various races, ages and genders, although this is not balanced. The number of lighter skin colored images are higher than darker skin images, more so for cyanotic images. Also, the number of images of young to middle-aged people is higher than the number of images of other age groups. This is due to the limited number and types of cyanotic images available on the internet. The dataset is included in our Github repository [5] .",
            "cite_spans": [
                {
                    "start": 625,
                    "end": 628,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Dataset."
        },
        {
            "text": "Classification algorithm. We implemented three classifiers: K nearest neighbors (KNN), logistic regression (LR) and support vector classifier (SVC). The input to these classifiers were frequency of pixel intensities from each channel (R, G, B channels) using a simple histogram with eighteen equally spaced bins (six for each of the three color channels). The rationale behind this was that the color distribution would be different in cyanotic and non-cyanotic lips, but there would be some colors in common. In other words, not all of the lip would be cyanotic, and some areas outside of the lip would be included. The bins representing these colors could then be regularized out. For the KNN algorithm, we used k=3 neighbors, uniform weights and the Euclidean distance metric. (We chose three clusters for the KNN to capture the two classes plus noise.) L2 regularization was used for the logistic regression implementation. For the SVC a regularization parameter C = 2 was chosen via grid search. Radial basis function kernel was used to make SVC a non-linear classifier. We used the sklearn package in Python3.7.3 for each of these implementations and used the default values for parameters not stated above.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Dataset."
        },
        {
            "text": "Febrile state detection. Fig. 6 shows the measurements used in the calibration process and the fitted results. The calibrated values of R and O were determined to be 580061 and 25113, respectively, and the resultant RMSE was 0.57 \u2022 C 2 . Fig. 7 shows the measured data points in the preliminary experiment, in which the proposed system achieved an RMSE of 0.41 \u2022 C and a Pearson correlation coefficient of 0.96. When applying 37.4 \u2022 C as the threshold for febrile state detection, an accuracy of 96.7% and an area under receiver operating characteristic curve (AUC) of 0.97 were achieved. 7 . Estimated temperature vs. temperature measured from thermometer. The correlation between the parameters was found to be 0.96 and the RMSE difference between them was 0.41 \u2022 C. 1, 2, 3 show the confusion matrices for each classifier. Fig. 8 shows the receiver operating characteristic curve and AUC of each classifier. Table 4 summarizes the accuracies, AUC, sensitivity and specificity of the three classification models. . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 25,
                    "end": 31,
                    "text": "Fig. 6",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 238,
                    "end": 244,
                    "text": "Fig. 7",
                    "ref_id": null
                },
                {
                    "start": 589,
                    "end": 590,
                    "text": "7",
                    "ref_id": null
                },
                {
                    "start": 769,
                    "end": 776,
                    "text": "1, 2, 3",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 826,
                    "end": 832,
                    "text": "Fig. 8",
                    "ref_id": null
                },
                {
                    "start": 911,
                    "end": 918,
                    "text": "Table 4",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Results"
        },
        {
            "text": "is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.04.09.20059840 doi: medRxiv preprint features by the logistic regression classifier, since this is easier to interpret that the parameters of the SVR or KNN. Fig.  9 shows the weights for the eighteen features used (six bins each for each of the three R, G and B channels). The first six features correspond to the red channel (R1 -R6). The next six features correspond to the green channel (G1 -G6) and the last six features correspond to the blue channel (B1 -B6).",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 265,
                    "end": 272,
                    "text": "Fig.  9",
                    "ref_id": null
                }
            ],
            "section": "Results"
        },
        {
            "text": "Forehead and lip segmentation. Detecting and segmenting out the forehead and lips is the first step in our pipeline. The accuracy of this stage can determine the accuracy of the remaining stages. This step is dependent on the performance of PoseNet, which sometimes has false positive detection of people. In this implementation, it is limited to detecting 10 people at a time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Fever detection. Previous meta-reviews suggest that peripheral temperature may not be sufficient to determine fever [21, 18] . This suggests that our proposed system, along with all traditional methods that measure peripheral temperature, like an ear thermometer, are not suitable to be used to perform an accurate diagnosis of febrile state. However, the proposed system is useful to perform mass early screening of the febrile state as a triage tool. The body temperature varies throughout the day in accordance with the circadian rhythm ( [6] , chapter 218). Taking this into account and having a dynamic threshold can reduce the number of false positive and false negative fever detection. Besides, body temperature could vary based on the ambient temperature. Having a reference temperature can help solve this issue. Additionally, the thermal camera in selection does not innately have the level of accuracy required for this task. Thus, a calibration for the targeted temperature range needs to be performed. However, the temperature calibration of the thermal camera is not a trivial task and can be inaccurate depending various aspects, like environmental temperature and surface condition. Also, a previous study suggests that improper use and interpretation of the infrared camera can lead to inaccurate triage [15] . Hence, it is important to understand that the proposed system is only reliable for the designated task under limited conditions. For example, the presence of common cosmetics or clothing such as a turban or hijab can affect the accuracy of the estimated temperature from thermal camera [30] . With a higher budget, the use of a thermal camera with higher accuracy and, if possible, one which is pre-calibrated can lead to a more reliable system. But a higher cost will inevitably lower the accessibility of the system. Cyanosis detection. For the detection of cyanosis, out of the three classification approaches evaluated, the SVC exhibited the highest accuracy (77.1%) and KNN has the highest AUC (0.93), although this is not significantly higher than the AUC of 0.91 for the SVR. The SVR also produces the fewest false negatives (missed cynaosis), which at triage, is probably the most important feature of this system. For the open source implementation, we therefore chose the SVR, although we note this is somewhat arbitrary at this point given the size of the data set we used.",
            "cite_spans": [
                {
                    "start": 116,
                    "end": 120,
                    "text": "[21,",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 121,
                    "end": 124,
                    "text": "18]",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 542,
                    "end": 545,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1322,
                    "end": 1326,
                    "text": "[15]",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 1615,
                    "end": 1619,
                    "text": "[30]",
                    "ref_id": "BIBREF34"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "To visualize the effect of the features on the overall classification we plot the LR coefficients for each features (see Fig.  9 ). It can be observed that the red channel exhibits higher importance for cyanosis detection. When creating a histogram of the pixel values with six equally spaced bins for each of the three color channels, it can be seen that every channel (R, G and B) contributes to the classification.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 121,
                    "end": 128,
                    "text": "Fig.  9",
                    "ref_id": null
                }
            ],
            "section": "Discussion"
        },
        {
            "text": "Limitations. We note that the lip cyanosis dataset we used is relatively small and contains relatively good quality images. In the wild, the quality of images is not guaranteed to be high. This may be due to variations in lighting, occlusions, movement, angle of presentation, distances much greater than 1m, among other issues. Consistency of ambient lighting is an important factor to ensure correct classification of cyanosis [6] . Camera parameters such as field of view and shutter speed can also influence the absolute color detected by the camera. Applying a color correction by using a color reference in the frame can solve this issue [2] . Cosmetics applied to and around the lip can also interfere with the classification. In practice, we observed that if the mouth is open or teeth are visible, the cyanosis classifications tend to be inaccurate. Lighting conditions also play a major role in the algorithm's output.",
            "cite_spans": [
                {
                    "start": 429,
                    "end": 432,
                    "text": "[6]",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 644,
                    "end": 647,
                    "text": "[2]",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "Perhaps the most important issue to consider is that of skin color and the variation of presentation of cyanosis across the human race. This is an under-explored area of research, but research into racial bias in facial recognition algorithms [4] has highlighted just how dangerous it can be to use these algorithms out-of-the-box, without tuning to a population or thought about the bias it can create.",
            "cite_spans": [
                {
                    "start": 243,
                    "end": 246,
                    "text": "[4]",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "In this work, we have proposed a system that can detect fever and cyanosis using a combination of visible light and thermal camera operating on an edge computation platform that is running state-of-the-art deep learning. The system does not require any direct interaction between the device and either patients or healthcare workers. The source code needed to replicate our proposed system can be found on Github [5] . It is important to note that PoseNet is image size and rotationally invariant (at least for most behaviors), and although we optimize the analysis to work at a 1m distance from the camera, this invariance should create a robustness to movement to and from the camera, as well as within the frame. Many improvements can be made to this system to increase the classification performance and stability, including larger population studies and end-to-end deep learning. However, the need for something is acute and will be increasingly so in low resource areas. We therefore feel it is appropriate to release this work prior to peer-review to solicit feedback and encourage others to improve the system.",
            "cite_spans": [
                {
                    "start": 413,
                    "end": 416,
                    "text": "[5]",
                    "ref_id": "BIBREF4"
                }
            ],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "Through this work, put together as a rapid response under a few days under lockdown, we hope to provide a starting point for automatic triage in clinical settings. Improving on this work could lead to novel implementations that can help streamline triage in clinics and hospitals, potentially during the current pandemic, where non-contact and rapid screening has distinct advantages for infection reduction.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "An Integrated Computerized Triage System in the Emergency Department",
            "authors": [
                {
                    "first": "Dominik",
                    "middle": [],
                    "last": "Aronsky",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "AMIA Annu Symp Proc",
            "volume": "",
            "issn": "",
            "pages": "1942--597",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Color Correction of Baby Images for Cyanosis Detection",
            "authors": [
                {
                    "first": "Nur Fatihah Binti",
                    "middle": [],
                    "last": "Azmi",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Medical Image Understanding and Analysis",
            "volume": "",
            "issn": "",
            "pages": "978--981",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification",
            "authors": [
                {
                    "first": "Joy",
                    "middle": [],
                    "last": "Buolamwini",
                    "suffix": ""
                },
                {
                    "first": "Timnit",
                    "middle": [],
                    "last": "Gebru",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the 1st Conference on Fairness",
            "volume": "81",
            "issn": "",
            "pages": "77--91",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "AutoTriage -An Open Source Raspberry Pi-based Clinical Screening System",
            "authors": [
                {
                    "first": "Chaitra",
                    "middle": [],
                    "last": "Hegde",
                    "suffix": ""
                },
                {
                    "first": "Zifan",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "Pradyumna",
                    "middle": [],
                    "last": "Byappanahalli Suresha",
                    "suffix": ""
                },
                {
                    "first": "Gari",
                    "middle": [
                        "D"
                    ],
                    "last": "Clifford",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Clinical methods: the history, physical, and laboratory examinations",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Vivian",
                    "suffix": ""
                },
                {
                    "first": "James A",
                    "middle": [],
                    "last": "Clark",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Kruse",
                    "suffix": ""
                }
            ],
            "year": 1990,
            "venue": "Jama",
            "volume": "264",
            "issn": "",
            "pages": "2808--2809",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Coronavirus (COVID-19) Media Information",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "2020--2024",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Canadian Agency for Drugs and Technologies in Health. Non-contact thermometers for detecting fever: a review of clinical effectiveness",
            "authors": [],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Fever Temperatures: Accuracy and Comparison",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "2020--2024",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Rev: 200. FLIR Systems. Mar",
            "authors": [],
            "year": 2018,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "A next generation electronic triage to aid mass casualty emergency medical response",
            "authors": [
                {
                    "first": "Tia",
                    "middle": [],
                    "last": "Gao",
                    "suffix": ""
                },
                {
                    "first": "David",
                    "middle": [],
                    "last": "White",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "International Conference of the IEEE Engineering in Medicine and Biology Society",
            "volume": "",
            "issn": "",
            "pages": "6501--6504",
            "other_ids": {
                "DOI": [
                    "file:/localhost/opt/grobid/grobid-home/tmp/10.1109/IEMBS.2006.260881"
                ]
            }
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Computer-aided simple triage (CAST) for coronary CT angiography (CCTA)",
            "authors": [
                {
                    "first": "Roman",
                    "middle": [],
                    "last": "Goldenberg",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "International journal of computer assisted radiology and surgery",
            "volume": "7",
            "issn": "6",
            "pages": "819--827",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "A Thermal Camera Based Continuous Body Temperature Measurement System\". en",
            "authors": [
                {
                    "first": "Jia-Wei",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                },
                {
                    "first": "Ming-Hung",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                },
                {
                    "first": "Yuan-Hsiang",
                    "middle": [],
                    "last": "Lin",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Emergency department crowding affects triage processes\". en",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Christien Van Der Linden",
                    "suffix": ""
                },
                {
                    "first": "Barbara",
                    "middle": [
                        "E A M"
                    ],
                    "last": "Meester",
                    "suffix": ""
                },
                {
                    "first": "Naomi",
                    "middle": [],
                    "last": "Van Der Linden",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "International Emergency Nursing. Special Issue: Triage",
            "volume": "29",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Fever screening and infrared thermal imaging: concerns and guidelines",
            "authors": [
                {
                    "first": "B",
                    "middle": [],
                    "last": "James",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Mercer",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Francis",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Ring",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Thermology International",
            "volume": "19",
            "issn": "",
            "pages": "67--69",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Most patients are triaged using the emergency severity index\". en",
            "authors": [
                {
                    "first": "Amir",
                    "middle": [],
                    "last": "Mirhaghi",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "J. Nucl. Cardiol",
            "volume": "24",
            "issn": "",
            "pages": "1071--3581",
            "other_ids": {
                "DOI": [
                    "http:/link.springer.com/10.1007/s12350-016-0704-z"
                ]
            }
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Accuracy and Reliability of Emergency Department Triage Using the Emergency Severity Index: An International Multicenter Assessment\". en",
            "authors": [
                {
                    "first": "Binoy",
                    "middle": [],
                    "last": "Mistry",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Annals of Emergency Medicine",
            "volume": "71",
            "issn": "5",
            "pages": "581--587",
            "other_ids": {
                "DOI": [
                    "10.1016/j.annemergmed.2017.09.036"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Emergency department crowding: a systematic review of causes, consequences and solutions",
            "authors": [
                {
                    "first": "Claire",
                    "middle": [],
                    "last": "Morley",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "PloS one 13",
            "volume": "8",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Another look at the persistent moral problem of emergency department crowding",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "John",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Moskop",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Annals of emergency medicine",
            "volume": "74",
            "issn": "",
            "pages": "357--364",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Comparison of rectal, axillary, and tympanic membrane temperatures in infants and young children\". en. In: Annals of",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Bruce",
                    "suffix": ""
                },
                {
                    "first": "",
                    "middle": [],
                    "last": "Muma",
                    "suffix": ""
                }
            ],
            "year": 1991,
            "venue": "Emergency Medicine",
            "volume": "20",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Analysis of IR thermal imager for mass blind fever screening\". en",
            "authors": [
                {
                    "first": "Eddie",
                    "middle": [
                        "Y"
                    ],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "J"
                    ],
                    "last": "Kawb",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Microvascular Research",
            "volume": "68",
            "issn": "2",
            "pages": "104--109",
            "other_ids": {
                "DOI": [
                    "10.1016/j.mvr.2004.05.003"
                ]
            }
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model",
            "authors": [
                {
                    "first": "George",
                    "middle": [],
                    "last": "Papandreou",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "The European Conference on Computer Vision (ECCV). Sept",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "ZSCC: NoCitationData",
            "authors": [
                {
                    "first": "Jesse",
                    "middle": [
                        "M"
                    ],
                    "last": "Pines",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "International Perspectives on Emergency Department Crowding\". en. In: Academic Emergency Medicine",
            "volume": "18",
            "issn": "",
            "pages": "1553--2712",
            "other_ids": {
                "DOI": [
                    "file:/localhost/opt/grobid/grobid-home/tmp/10.1111/j.1553-2712.2011.01235.x"
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "You Only Look Once: Unified, Real-Time Object Detection",
            "authors": [
                {
                    "first": "Joseph",
                    "middle": [],
                    "last": "Redmon",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Detecting Fever in Polish Children by Infrared Thermography\". en",
            "authors": [
                {
                    "first": "E",
                    "middle": [
                        "F J"
                    ],
                    "last": "Ring",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the 2008 International Conference on Quantitative InfraRed Thermography. ZSCC: NoCitationData",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Mobile-platform for automatic fever screening system based on infrared forehead temperature\". en",
            "authors": [
                {
                    "first": "Armote",
                    "middle": [],
                    "last": "Somboonkaew",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 Opto-Electronics and Communications Conference (OECC) and Photonics Global Conference (PGC)",
            "volume": "",
            "issn": "",
            "pages": "1--4",
            "other_ids": {
                "DOI": [
                    "10.1109/OECC.2017.8114910"
                ]
            }
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "13154: Medical electrical equipment-Deployment, implementation and operational guidelines for identifying febrile humans using a screening thermograph",
            "authors": [
                {
                    "first": "",
                    "middle": [],
                    "last": "Isoiso Tr",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "International Organization for Standardization",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF33": {
            "ref_id": "b33",
            "title": "Swamped: Emergency Department Crowding and Patient Mortality",
            "authors": [
                {
                    "first": "Lindsey",
                    "middle": [],
                    "last": "Woodworth",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Journal of Health Economics",
            "volume": "70",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF34": {
            "ref_id": "b34",
            "title": "Infrared assessment of human facial temperature in the presence and absence of common cosmetics. en. preprint. ZSCC: 0000000. Epidemiology",
            "authors": [
                {
                    "first": "Kaikai",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "http:/medrxiv.org/lookup/doi/10.1101/2020.03.12.20034793"
                ]
            }
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Hardware configuration consisting of a Raspberry Pi 4 (4 GB RAM), a Google Coral USB accelerator (top), a RasPi Camera v2 and a FLIR Lepton 3.5 Radiometry Long-Wave Infrared Camera.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Installation of system with all cabling including power and external monitor for visualization (not show, or needed for detection).",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "AutoTriage pipeline. The purple boxes denote inputs and outputs at different stages. The green boxes denote computations.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Bounding boxes detected for the forehead and lips from a 1m range in visible light video (upper image) and thermal video (lower image) using PoseNet.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Illustration of the water calibration experiment. The bright spot in the lower left quadrant of the FLIR output represents the water heated to varying known temperatures. where S denotes the output pixel value from the FLIR Lepton, T denotes the actual temperature and R, B, F, O are parameters required for the conversion. Within the FLIR Lepton's operating temperature range, the typical values of F and B are 1 and 1428, respectively. We used bottles (with open lids) of heated water with temperature ranging from 35 \u2212 40 \u2022 C as a heat source and located them at one meter to the camera and approximately in the center of the field of view (FOV). (See Fig.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Calibration of FLIR images using a bottle of water: The least square curve of best fit between the average temperature from the thermometer and the FLIR pixel values had a root mean square error (RMSE) of 0.57 \u2022 C.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig. 7. Estimated temperature vs. temperature measured from thermometer. The correlation between the parameters was found to be 0.96 and the RMSE difference between them was 0.41 \u2022 C.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Receiver Operating Characteristic Curves for the three classifiers evaluated in this work for cyanosis detection. The filled circles represent the operating points resulting in the other performance statistics. (Small differences exist due to the LOOCV approach.) Weighting of features from logistic regression. The features are the histogram values the R, G and B channels. Positive coefficients refer to cyanotic condition and negative refer to non-cyanotic.To assess the relative importance of the features used for classification, we visualized the weights assigned to different Hegde, Jiang et al. | AutoTriage medR\u03c7iv | 5",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Confusion Matrix for KNN for cyanosis detection. detection. Tables",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "Confusion Matrix for LR for cyanosis detection.",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Confusion Matrix for SVC for cyanosis detection.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Performance of assessed cyanosis detection classifiers.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "This work was spun out from work funded by gifts from the Cox Foundation and the Center for Discovery.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ACKNOWLEDGEMENTS"
        }
    ]
}